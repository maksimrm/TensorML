{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries\n",
    "You will need ***numpy*** and ***matplotlib***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPA class contains all necessary functions for processing with one-dimensional tensor networks.\n",
    "MPA is a direct high dimensional generalization of MPS (MPS has one physical index whereas MPA has multiple physical indices.)\n",
    "We can organize our class as follows:\n",
    "- the object of the class contains a list of local tensors (in the case of MPS one corresponds to $\\left\\{A^{(n)}_{ikj}\\right\\}_{n=1}^{N}$),, number of states, the shape of \"physical\" space, list of bond dims.\n",
    "- Objects of MPA class must have the same shape of all site physical indices, bond dims can be arbitrary\n",
    "- MPA class includes the following list of methods and functions: reshape, transpose, complex conjugate, einsum (local convolutions), evaluate, truncation, ability to create random mpa, etc.\n",
    " As a part of the task, you have to fill gaps in the code below (№0): Import necessary libraries. \n",
    " We recommend to take a time and examine in details all methods in the follwoing class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPA:\n",
    "    \n",
    "    \n",
    "    '''the init function initializes an object of the class. As an input, the function takes\n",
    "    list of local tensors of shape (left, n1, n2, ..., nk, right), where left is the left bond dim.,\n",
    "    right is the right bond dim. and n1, n2, ..., nk is the shape of physical space.'''\n",
    "    def __init__(self, list_of_tensors):\n",
    "        \n",
    "        #the list of local tensors in the body of an object\n",
    "        self.list_of_tensors = list_of_tensors\n",
    "        \n",
    "        #the number of sites in the body of an object\n",
    "        self.num_sites = len(list_of_tensors)\n",
    "        \n",
    "        #here we check that physical shapes of each local tensor are the same\n",
    "        for i in range(1, self.num_sites):\n",
    "            if list_of_tensors[i-1].shape[1:-1] != list_of_tensors[i].shape[1:-1]:\n",
    "                raise ValueError(\"INCORRECT ONE SITE SHAPES\")\n",
    "        \n",
    "        #here we check that bond dims of all local tensors are \"stackable\"\n",
    "        for i in range(1, self.num_sites):\n",
    "            if list_of_tensors[i-1].shape[-1] != list_of_tensors[i].shape[0]:\n",
    "                raise ValueError(\"INCORRECT BOND DIM.\")\n",
    "        \n",
    "        #the site shape (shape of physical space) in the body of an object\n",
    "        self.site_shape = list_of_tensors[0].shape[1:-1]\n",
    "        \n",
    "        #the list of bond dims in the body of aa object\n",
    "        self.bond_dims = [list_of_tensors[0].shape[0]] + [tensor.shape[-1] for tensor in list_of_tensors]\n",
    "        \n",
    "    '''the method reshapes the physical part of a local tensor, as an input, \n",
    "                  the method takes new shape (tuple) The method returns MPA object with a new shape.'''\n",
    "    def reshape(self, shape):\n",
    "        #the following list will be filled by reshaped local tensors\n",
    "        list_of_tensors = []\n",
    "        \n",
    "        #the loop over all local tensors\n",
    "        for i, tensor in enumerate(self.list_of_tensors):\n",
    "            \n",
    "            list_of_tensors.append(tensor.reshape([tensor.shape[0],]+list(shape)+[tensor.shape[-1],]))\n",
    "            \n",
    "            #here you have to fill list_of_tensors by reshaped local tensors\n",
    "            #(hint: use np.reshape and atribute .shape)\n",
    "            # ENTER YOUR CODE ##\n",
    "            \n",
    "        return MPA(list_of_tensors)\n",
    "    \n",
    "    '''the method transposes the phycical part of a local tensor, as an input the method takes new order of physical\n",
    "    indices. The method returns MPA object with a new shape.'''\n",
    "    def transpose(self, tuple_of_indeces):\n",
    "        #the following list will be filled by transposed local tensors\n",
    "        list_of_tensors = []\n",
    "        indeces = tuple((i+1 for i in tuple_of_indeces))\n",
    "        \n",
    "        #the loop over all local tensors\n",
    "        for i, tensor in enumerate(self.list_of_tensors):\n",
    "            \n",
    "            list_of_tensors.append(tensor.transpose((0,)+indeces[::-1]+(len(tensor.shape)-1,)))\n",
    "            \n",
    "            # avoid any transpositions of bond indices, operate only with physical ones! You can encode \n",
    "            # your transpostion of phys. indeces wich must be taken as tuple\n",
    "            # ENTER YOUR CODE\n",
    "        return MPA(list_of_tensors)\n",
    "\n",
    "    '''the method perform complex conjugation of all local tensors.''' \n",
    "    def conj(self):\n",
    "        #the following  list must be filled by conj. local tensors \n",
    "        list_of_tensors = []\n",
    "        #use statndart method of numpy lib  -.conj # \n",
    "        for i, tensor in enumerate(self.list_of_tensors):\n",
    "            list_of_tensors.append(tensor.conj())\n",
    "        return MPA(list_of_tensors)\n",
    "   \n",
    "    '''the method performs physical indeces arbitrary convolution of two adjustent local tensors. \n",
    "    It is generalization on numpy's np.einsum''' \n",
    "    @staticmethod   \n",
    "    def einsum(string, mpa1, mpa2):\n",
    "        \n",
    "        #preparing einsum string for local tensors\n",
    "        #here we give you hint how deal with bond indices\n",
    "        inp, out = string.split('->')\n",
    "        inp_a, inp_b = inp.split(',')\n",
    "        corr_inp_a = 'w' + inp_a + 'x'\n",
    "        corr_inp_b = 'y' + inp_b + 'z'\n",
    "        corr_out = 'wy' + out + 'xz'\n",
    "        corr_string = corr_inp_a + ',' + corr_inp_b + '->' + corr_out\n",
    "        \n",
    "        #Here we ask - are the lengths of mps arrays equal?\n",
    "        assert len(mpa1.list_of_tensors) == len(mpa2.list_of_tensors), 'mp arrays have different lenght'\n",
    "        \n",
    "        #the following list must be filled by convoluted local tensors \n",
    "        new_list_of_tensors = []\n",
    "        #loop over all local tensors #\n",
    "        for i in range(len(mpa1.list_of_tensors)):\n",
    "            #use string ( corr_string) below as argument of numpy's np.einsum \n",
    "            # ENTER YOUR CODE ##\n",
    "            #Here we reshape bond dims to give a correct form of new local tensors \n",
    "            tensor = np.einsum(corr_string, mpa1.list_of_tensors[i], mpa2.list_of_tensors[i])\n",
    "            shape = tensor.shape\n",
    "            tensor = tensor.reshape((-1,) + shape[2:-2] + (shape[-2]*shape[-1],))\n",
    "            new_list_of_tensors.append(tensor)\n",
    "            \n",
    "        \n",
    "        return MPA(new_list_of_tensors)\n",
    "        \n",
    "    \n",
    "   \n",
    "    '''This method allows one to create a random MPA '''\n",
    "    @staticmethod\n",
    "    \n",
    "    def random_mpa(num_sites, site_shape, bond_dim):\n",
    "        \n",
    "        left_shape = (1,) + site_shape + (bond_dim,)\n",
    "        mid_shape =  (bond_dim,) + site_shape + (bond_dim,)\n",
    "        right_shape = (bond_dim,) + site_shape + (1,)\n",
    "        left_tensor = np.random.randn(*left_shape) + np.random.randn(*left_shape) * 1j\n",
    "        mid_tensor = np.random.randn(*mid_shape) + np.random.randn(*mid_shape) * 1j\n",
    "        right_tensor = np.random.randn(*right_shape) + np.random.randn(*right_shape) * 1j\n",
    "        list_of_tensors = [left_tensor] + (num_sites - 2) * [mid_tensor] + [right_tensor]\n",
    "        return MPA(list_of_tensors)\n",
    "    \n",
    "    '''This method allows one to return value of local tensor with respect to the given index'''\n",
    "    def value_mps(self, indeces):\n",
    "        assert len(self.list_of_tensors[0].shape[1:-1]) == 1, \"GIVEN MPA IS NOT MPS\"\n",
    "        in_tensor = self.list_of_tensors[0][:, indeces[:, 0], :]\n",
    "        for i in range(1, len(self.list_of_tensors)):\n",
    "            update_tensor = self.list_of_tensors[i][:, indeces[:, i], :]\n",
    "            in_tensor = np.einsum('ijk,kjl->ijl', in_tensor, update_tensor)\n",
    "        return in_tensor.flatten()\n",
    "    '''This method allows one to calculate a norm of MPS state. Note, this method  is inplace method!!!'''\n",
    "    def norm_psi(self):\n",
    "        assert len(self.list_of_tensors[0].shape[1:-1]) == 1, \"GIVEN MPA IS NOT MPS\"\n",
    "        local_tensor = self.list_of_tensors[0]\n",
    "        in_tensor = np.einsum('ijk,ljm->ilkm', local_tensor, local_tensor.conj())\n",
    "        norm = np.linalg.norm(in_tensor)\n",
    "        in_tensor = in_tensor / norm\n",
    "        self.list_of_tensors[0] = local_tensor / np.sqrt(norm)\n",
    "        for i in range(1, len(self.list_of_tensors)):\n",
    "            update_tensor = np.einsum('ijk,ljm->ilkm', self.list_of_tensors[i], self.list_of_tensors[i].conj())\n",
    "            in_tensor = np.einsum('ijkm,kmln->ijln', in_tensor, update_tensor)\n",
    "            norm = np.linalg.norm(in_tensor)\n",
    "            self.list_of_tensors[i] = self.list_of_tensors[i] / np.sqrt(norm)\n",
    "            in_tensor = in_tensor / norm\n",
    "\n",
    "    '''This method allows one to convolute MPS'''\n",
    "    def evaluate(self):\n",
    "        assert len(self.site_shape) == 0, \"MPA IS NOT FULLY CONVOLUTED\"\n",
    "        local_tensor = self.list_of_tensors[0]\n",
    "        local_tensor = local_tensor.reshape((local_tensor.shape[0],) + (local_tensor.shape[-1],))\n",
    "        for i in range(1, len(self.list_of_tensors)):\n",
    "            update_tensor = self.list_of_tensors[i]\n",
    "            update_tensor = update_tensor.reshape((update_tensor.shape[0],) + (update_tensor.shape[-1],))\n",
    "            local_tensor = local_tensor.dot(update_tensor)\n",
    "        return local_tensor.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The part №1\n",
    "You have to experiment and get comfortable with basic operations over MPA/MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.201401714513318\n"
     ]
    }
   ],
   "source": [
    "#Test part:\n",
    "np.random.seed(11)\n",
    "#Create random mps for spin chain of size N = 32, bond dims = 5\n",
    "a = MPA.random_mpa(32, (2,), 5)\n",
    "#Culculate conjugated state \n",
    "b = a.conj()\n",
    "#Perform convolution of original mps with conjugated one over all physical indeces\n",
    "conv = MPA.einsum(\"j,j->\", a, b)\n",
    "print(np.real(conv.list_of_tensors[0][0, 0])) #THIS NUMBER IS AN ANSWER FOR THE TEST!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.34654453e+39] [1.]\n"
     ]
    }
   ],
   "source": [
    "#Create random mps for spin chain of size N = 32, bond dims = 5 \n",
    "np.random.seed(11)\n",
    "mps1 = MPA.random_mpa(32, (2,),5)\n",
    "\n",
    "#Perform Normalization procedure over your mps1\n",
    "first = MPA.einsum(\"j,j->\", mps1, mps1.conj())\n",
    "first  = first.evaluate()\n",
    "mps1.norm_psi()\n",
    "# ENTER YOUR CODE\n",
    "#Culculate conjugated state \n",
    "norm = MPA.einsum(\"j,j->\", mps1, mps1.conj())\n",
    "# norm.norm_psi()\n",
    "norm = norm.evaluate()\n",
    "# ENTER YOUR CODE\n",
    "#Calculate normalization coefficient manualy: norm = <psi|psi> (after normalization of state norm must be equal to 1)\n",
    "\n",
    "\n",
    "\n",
    "print(abs(first), abs(norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Task: Consider GHZ state. Using ypur class represent GHZ state in MPS from.\n",
    "Eneter you reslts for N=100 particles:\n",
    "1. num_sites = \n",
    "2. list of dims = \n",
    "3. normalization constant = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GHZ in MPS form\n",
    "GHZ = np.ones([2 for i in range(5)])/np.sqrt(2)\n",
    "\n",
    "\n",
    "# ENTER YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_tesors = []\n",
    "\n",
    "q, r, e = np.linalg.svd(GHZ.reshape(2, -1))\n",
    "\n",
    "\n",
    "list_of_tesors.append(q.reshape((1,)+q.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (16,16) not aligned: 2 (dim 0) != 16 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-6ce3e6b8dd59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,) and (16,16) not aligned: 2 (dim 0) != 16 (dim 0)"
     ]
    }
   ],
   "source": [
    "q, r, e = np.linalg.svd(np.dot(r,e).reshape(2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 2, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,6],[3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reshape([1,]+list((2,3))+[1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (1,)+(2,3)+(4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 2, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 6],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 6.40720741+0.j        , -1.01756989-1.04170477j,\n",
       "          -2.57459432-2.15354348j, -3.55488448+3.86454709j,\n",
       "           2.89638941-0.3657899j ],\n",
       "         [-1.01756989+1.04170477j,  1.77111956+0.j        ,\n",
       "           0.10629547+0.5845732j , -0.3667495 -0.93680414j,\n",
       "           0.0763595 -0.76268011j],\n",
       "         [-2.57459432+2.15354348j,  0.10629547-0.5845732j ,\n",
       "           4.22903579+0.j        ,  2.99529908-4.61384712j,\n",
       "          -1.48258073-0.0815526j ],\n",
       "         [-3.55488448-3.86454709j, -0.3667495 +0.93680414j,\n",
       "           2.99529908+4.61384712j,  9.96462551+0.j        ,\n",
       "          -0.05986041-3.174527j  ],\n",
       "         [ 2.89638941+0.3657899j ,  0.0763595 +0.76268011j,\n",
       "          -1.48258073+0.0815526j , -0.05986041+3.174527j  ,\n",
       "           4.03355897+0.j        ]]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('mjl,ejr->melr',a.list_of_tensors[0],b.list_of_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.list_of_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,8,0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1\n",
      "1 : 2\n",
      "2 : 3\n",
      "3 : 4\n",
      "4 : 5\n",
      "5 : 6\n",
      "6 : 7\n",
      "7 : 8\n",
      "8 : 0\n",
      "9 : 9\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(a):\n",
    "    print(\"{} : {}\".format(i, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
